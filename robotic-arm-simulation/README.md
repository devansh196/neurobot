# ğŸ¤–ğŸ§  NLP-Controlled Robotic Arm Simulator



## ğŸš€ Overview

This project provides a **web-based interface** to control a **PyBullet robotic arm** using **natural language commands**. It supports:

* Pick-and-place actions
* Directional movements (upar, nichay, daye, baye)
* Real-time physics simulation
* Integration with EEG/BCI systems



## âœ¨ Features

### ğŸ”¹ Natural Language Command Parsing

* Understands English + Hinglish commands
* Detects actions (pick, place, grab)
* Detects objects (bottle, ball)
* Detects destinations (red box, blue box)
* Supports directional gestures

### ğŸ”¹ Realistic Robot Motion

* PyBullet-based simulation
* Inverse kinematics for smooth arm control
* Human-like shoulderâ€‘based movement for direction commands

### ğŸ”¹ Object Pick & Place

* Pick objects (bottle/ball)
* Place into red or blue box
* Automatic object coordinate detection via virtual camera

### ğŸ”¹ Web Interface

* Flask backend
* Live command execution
* Simple and responsive UI



## ğŸ“¦ Requirements

```
pip install Flask spacy pybullet
python -m spacy download en_core_web_sm
```

> `app.py` auto-downloads the spaCy model if missing.

---

## â–¶ï¸ How to Run

1. Install dependencies
2. Run the Flask server:

```
python app.py
```

3. Open:

```
http://127.0.0.1:5000/
```

---

## ğŸ—£ï¸ Supported Commands

### **Pick & Place**

* "pick bottle"
* "place bottle on red box"

### **Directional Commands**

| Command    | Meaning | Axis |
| ---------- | ------- | ---- |
| **upar**   | Up      | +Z   |
| **nichay** | Down    | -Z   |
| **daye**   | Right   | +Y   |
| **baye**   | Left    | -Y   |

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ simulation/
â”‚   â”œâ”€â”€ pybullet_env.py
â”‚   â”œâ”€â”€ robot_control.py
â”‚   â””â”€â”€ camera_control.py
â””â”€â”€ templates/
    â””â”€â”€ index.html
```

---

## ğŸ§  EEG Integration

Designed for EEG-based control:

```
EEG Signal â†’ Decoder Model â†’ Text Command â†’ Flask â†’ Robot Action
```

---

